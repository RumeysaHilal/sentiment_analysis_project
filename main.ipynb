{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis from IMDB Movie Review Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Install the NLTK stopwords list (only need for first time)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# This list contains common words like 'the', 'a', 'is', etc. \u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sb\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Install the NLTK stopwords list (only need for first time)\n",
    "# This list contains common words like 'the', 'a', 'is', etc. \n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "\n",
      "Sentiment Distribution:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get an overview of the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()\n",
    "\n",
    "# Control the disribution of 'sentiment' column in the dataset\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get meaningless words as a list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This function cleans the raw text\n",
    "    \"\"\"\n",
    "    # Remove the HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting text cleaning...(This may take a while)\n",
      "Text cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting text cleaning...(This may take a while)\")\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "print(\"Text cleaning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning Data:\n",
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  one reviewers mentioned watching 1 oz episode ...  \n",
      "1  wonderful little production filming technique ...  \n",
      "2  thought wonderful way spend time hot summer we...  \n",
      "3  basically theres family little boy jake thinks...  \n",
      "4  petter matteis love time money visually stunni...  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCleaning Data:\")\n",
    "print(df[['review', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Text to Numerical Format (Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to numerical values\n",
    "df['sentiment_numeric'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split dataset as features (X) and target (y)\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment_numeric']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "# max_features=5000 : use the most common 5000 words \n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Create logistic regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('log_reg', log_reg)])\n",
    "\n",
    "# Train the model on the training data\n",
    "print(\"\\nTraining model...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation the Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of Model: 0.890\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.88      0.89      5000\n",
      "    Positive       0.88      0.90      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy of Model: {accuracy:.3f}\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred,target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MOdel with New Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: This movie was amazing, I loved every minute of it.\n",
      "-->Predicted Sentiment: Positive\n",
      "    (Confidence: Negative=0.01, Positive=0.99)\n",
      "\n",
      "Review: The plot was confusing and the acting was bad.\n",
      "-->Predicted Sentiment: Negative\n",
      "    (Confidence: Negative=0.99, Positive=0.01)\n",
      "\n",
      "Review: The movie was okay, nothing special.\n",
      "-->Predicted Sentiment: Negative\n",
      "    (Confidence: Negative=0.97, Positive=0.03)\n",
      "\n",
      "Review: The acting was great, but the plot was bad.\n",
      "-->Predicted Sentiment: Negative\n",
      "    (Confidence: Negative=0.89, Positive=0.11)\n",
      "\n",
      "Review: The movie was great, I loved it!\n",
      "-->Predicted Sentiment: Positive\n",
      "    (Confidence: Negative=0.00, Positive=1.00)\n"
     ]
    }
   ],
   "source": [
    "# New reviews for testing the model\n",
    "new_reviews = [\n",
    "    \"This movie was amazing, I loved every minute of it.\",\n",
    "    \"The plot was confusing and the acting was bad.\",\n",
    "    \"The movie was okay, nothing special.\",\n",
    "    \"The acting was great, but the plot was bad.\",\n",
    "    \"The movie was great, I loved it!\"\n",
    "]\n",
    "\n",
    "# Make predictions on the new reviews\n",
    "predicted_sentiments = pipeline.predict(new_reviews)\n",
    "\n",
    "# See the predict probabilities\n",
    "predicted_propabilities = pipeline.predict_proba(new_reviews)\n",
    "\n",
    "for review, sentiment, probs in zip(new_reviews, predicted_sentiments, predicted_propabilities):\n",
    "    sentiment_label = 'Positive' if sentiment == 1 else 'Negative'\n",
    "    print(f\"\\nReview: {review}\")\n",
    "    print(f\"-->Predicted Sentiment: {sentiment_label}\")\n",
    "    print(f\"    (Confidence: Negative={probs[0]:.2f}, Positive={probs[1]:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
